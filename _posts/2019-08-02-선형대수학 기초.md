---
title: 선형대수학 기초
author: M.Y.
layout : post
---



Linear : linear combination 관계가 유지
$$
v= au+bw
$$
then, 
$$
v'=au'+bw'
$$


```
연립 방정식의 해  

~ 행렬 Ax=b

~ basis transform (A의 column vector는 변환 후 basis vector)

~ function(=Linear Transform) 
```



이는 모두 vector space 로 linear combination 등의 개념을 공유하고 있다.

- linear combination  : scalar multiplication and vector addition 

- basis, span 

- linear composition AA'

- linearly independent :  c1v1+c2v2+.....=0 의 해가 c1=c2=c3=...=0로 유일하다

  > An,n 
  >
  > Rn의 basis이다. 
  >
  > rank=n , nullity=0
  >
  > dimension reduction이 일어나지 않는다.  즉, Ax=b의 해가 유일하다. 즉 inversable한 nonsingular matrix이다. elementary matrix의 곱으로 나타낼 수 있으며 단위행렬과 동치이다.
  >
  > Det(A) =/= 0  (=면적 비)

  > Am,n
  >
  > rank(A)+nullity(A)=n : n차원의 벡터는 rank(A)차원으로 linear transform 되면서 rank(A)가 n 보다 작은 경우 여러 개의 벡터가 하나의 벡터가 되며 (nondeterministic solution)  여러개의 벡터는 nullity(A)의 차원 만큼 존재. 예를 들어, 3차원(n)-> 2차원(rank)이라면 2차원+  1차원벡터= 3차원 공간 표현 가능, 다른 말로 1차원 벡터로 표현할수 있는 공간이 하나의 점으로 표현 
  >
  > dim(column space) = dim(row space)

- Basis transformation  B->B' = B'B-1

  > B : standard basis-> B basis 
  >
  > 만 기억하면 쉽게 이해된다

- one-to-one (rank(A)=n), onto (rank(A)=m) , isomorphism  An,n

- 기본 연산 1: Gaussian(-Jordan) Elimination

  > basis, rank, solution, inverse 계산

- 기본 연산 2: LU- decomposiotion

  > Ax=b
  >
  > LUx=b
  >
  > Ly=b  front substitution
  >
  > Ux=y back substitution
  >
  > solution 계산이 효율적 ( b가 달라져도 eliminaton 한번 )

- Transpose, inverse, determinant, Symmetric matrix 

  > At=A : Symmetric
  >
  > det(A-1)= 1/det(A)  
  >
  > det(AT)=det(A)
  >
  > det(diagonal matrix)= πaii

- determinant 연산 

- 기본연산3 : Crammer rule 

  > det로 해 계산 

- Inner product space  : norm, length,distance

  > <u,u>=||u||^2
  >
  > angle, projection, triangular rule...

- Orthogonal, Orthonormal : <u,v>=0

  > orthogonal하면 linearly independent 하다 (= inversable)
  >
  > w=<w,v1>v1+<w,v2>v2+... 이다. 즉 innerproduct 값이 해(= 좌표) 
  >
  > orthogonal하면 At=A-1이다

- 기본연산 3: Gram-Schmidt Orthonormalization 

  > basis를 Orthonormal basis로 변환하는 연산

- eigen vector, eigen value : A**v** = λ**v**

  > 의미: A변환후에도 scale만 변하는 벡터 
  >
  > 계산: det(λI-A)=0 로 λ(eigen value)를 구하고 (A-λI)v=0 으로 v (eigen vector)계산 
  >
  > triangular matrix는 대각원소가 eigen value
  >
  > Symmetric matrix는 항상 대각화가 가능하며 이때 eigen vector는 orthogonal 
  >
  > linearly independent 한 n개의 eigen vector가 존재하는 경우 A는 diagonizable하다. A'는 diagonal matrix가 된다.   A=PA'P-1  (P: eigen vector) 이경우 A의 inverse , det, A^100 를 쉽게 구할 수 있다.

  ![1564823929866](C:\Users\myson\AppData\Roaming\Typora\typora-user-images\1564823929866.png)

- A'=P-1AP , A=PA'P-1   

  > 해석: A는 변환, A'는 P가 basis일때 A의 변환 , world coordinate를 기준으로 좌표계를 맞췄다가 변환하고 다시 원래 위치로 보낸다고 이해할 수 있다.

- singular decomposition Am,n 

  AAt eigen vector U

  AtA eigen vector V

  AAt 또는 AtA의 sqaurt(eigen value)   Σ

  A= UΣVt

>  Σ의 rank 축소 = A rank 축소 =노이즈 제거, 압축 
>
> :The rank of *A* equals the number of non-zero [singular values]

- least squre, pseudo inverse for non inversable A

  > Ax=b
  >
  > x=A"b
  >
  > A"= UtΣ"V
  >
  > Least square : x= (AtA)-1At b

  